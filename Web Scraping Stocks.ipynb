{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tidying HTML\n",
    "- simple parallelization\n",
    "- Storing Snapshots by using python dill\n",
    "- Exploration\n",
    "- Stock selection using simple filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:20:43.809671Z",
     "start_time": "2018-08-12T10:20:43.806083Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # pandas for dataframe based data processing and CSV file I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:20:40.114565Z",
     "start_time": "2018-08-12T10:20:38.508013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytidylib\n",
      "  Downloading pytidylib-0.3.2.tar.gz (87 kB)\n",
      "Building wheels for collected packages: pytidylib\n",
      "  Building wheel for pytidylib (setup.py): started\n",
      "  Building wheel for pytidylib (setup.py): finished with status 'done'\n",
      "  Created wheel for pytidylib: filename=pytidylib-0.3.2-py3-none-any.whl size=8551 sha256=452c6430d5256853c4af1ac06777c96243dc5455b9bdf9acd28fd6622a463f2e\n",
      "  Stored in directory: c:\\users\\ainap\\appdata\\local\\pip\\cache\\wheels\\9b\\e4\\23\\8f81a76c9f2535ee091f118948202c8821ac671b7dbe41208b\n",
      "Successfully built pytidylib\n",
      "Installing collected packages: pytidylib\n",
      "Successfully installed pytidylib-0.3.2\n"
     ]
    }
   ],
   "source": [
    "import requests # for http requests\n",
    "from bs4 import BeautifulSoup # for html parsing and scraping\n",
    "#!pip install fastnumbers\n",
    "from fastnumbers import isfloat \n",
    "from fastnumbers import fast_float\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "import bs4\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "!pip install pytidylib\n",
    "from tidylib import tidy_document # for tidying incorrect html\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:21:24.948246Z",
     "start_time": "2018-08-12T10:21:24.927870Z"
    }
   },
   "outputs": [],
   "source": [
    "def ffloat(string):\n",
    "    if string is None:\n",
    "        return np.nan\n",
    "    if type(string)==float or type(string)==np.float64:\n",
    "        return string\n",
    "    if type(string)==int or type(string)==np.int64:\n",
    "        return string\n",
    "    return fast_float(string.split(\" \")[0].replace(',','').replace('%',''),\n",
    "                      default=np.nan)\n",
    "\n",
    "def ffloat_list(string_list):\n",
    "    return list(map(ffloat,string_list))\n",
    "\n",
    "def remove_multiple_spaces(string):\n",
    "    if type(string)==str:\n",
    "        return ' '.join(string.split())\n",
    "    return string\n",
    "\n",
    "def get_children(html_content):\n",
    "    children = list()\n",
    "    for item in html_content.children:\n",
    "        if type(item)==bs4.element.Comment:\n",
    "            continue\n",
    "        if type(item)==bs4.element.Tag or len(str(item).replace(\"\\n\",\"\").strip())>0:\n",
    "            children.append(item)\n",
    "        \n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:21:49.381898Z",
     "start_time": "2018-08-12T10:21:49.367200Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_table_simple(table,is_table_tag=True):\n",
    "    elems = table.find_all('tr') if is_table_tag else get_children(table)\n",
    "    table_data = list()\n",
    "    for row in elems:\n",
    "        \n",
    "        row_data = list()\n",
    "        row_elems = get_children(row)\n",
    "        for elem in row_elems:\n",
    "            text = elem.text.strip().replace(\"\\n\",\"\")\n",
    "            text = remove_multiple_spaces(text)\n",
    "            if len(text)==0:\n",
    "                continue\n",
    "            row_data.append(text)\n",
    "        table_data.append(row_data)\n",
    "    return table_data\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML Tidying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without Tidying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove a closing </tr> from previous html and see if BeautifulSoup can parse it correctly. Look for closing tr of July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T15:22:49.134925Z",
     "start_time": "2018-07-28T15:22:49.127077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Month', 'Price'],\n",
       " ['July', '2', 'August4', 'September3', 'October2'],\n",
       " ['August', '4'],\n",
       " ['September', '3'],\n",
       " ['October', '2']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = '''\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>Month</td>\n",
    "        <td>Price</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>July</td>\n",
    "        <td>2</td>\n",
    "    \n",
    "    <tr>\n",
    "        <td>August</td>\n",
    "        <td>4</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>September</td>\n",
    "        <td>3</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>October</td>\n",
    "        <td>2</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "'''\n",
    "\n",
    "content = BeautifulSoup(html,\"html.parser\")\n",
    "get_table_simple(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Tidying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T15:22:49.955822Z",
     "start_time": "2018-07-28T15:22:49.942860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytidylib in c:\\users\\ainap\\anaconda3\\lib\\site-packages (0.3.2)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Could not load libtidy using any of these names: libtidy,libtidy.so,libtidy-0.99.so.0,cygtidy-0-99-0,tidylib,libtidy.dylib,tidy",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-483460f5570d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtidylib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtidy_document\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtidylib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtidy_fragment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtidy_fragment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mhtml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"html.parser\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tidylib\\tidy.py\u001b[0m in \u001b[0;36mtidy_fragment\u001b[1;34m(text, options, keep_doc)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkeep_doc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKEEP_DOC_WARNING\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mget_module_tidy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtidy_fragment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tidylib\\tidy.py\u001b[0m in \u001b[0;36mget_module_tidy\u001b[1;34m()\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0m_tidy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'_tidy'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m         \u001b[0m_tidy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTidy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_tidy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tidylib\\tidy.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, lib_names)\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tidy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             raise OSError(\n\u001b[0m\u001b[0;32m     98\u001b[0m                 \u001b[1;34m\"Could not load libtidy using any of these names: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                 + \",\".join(lib_names))\n",
      "\u001b[1;31mOSError\u001b[0m: Could not load libtidy using any of these names: libtidy,libtidy.so,libtidy-0.99.so.0,cygtidy-0-99-0,tidylib,libtidy.dylib,tidy"
     ]
    }
   ],
   "source": [
    "!pip install pytidylib\n",
    "from tidylib import tidy_document\n",
    "from tidylib import tidy_fragment\n",
    "html, errors = tidy_fragment(html)\n",
    "html.replace(\"\\n\",\"\")\n",
    "content = BeautifulSoup(html,\"html.parser\")\n",
    "get_table_simple(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the tidying added a </tr> at the right place and we got our content parsed properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Lib for fetching details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T09:29:16.618774Z",
     "start_time": "2018-08-10T09:29:16.595899Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_ratios(url):\n",
    "    page_response = requests.get(url, timeout=240)\n",
    "    page_content, errors = tidy_document(page_response.content,options={'numeric-entities':1})\n",
    "    page_content = BeautifulSoup(page_content, \"html.parser\")\n",
    "    table_content = page_content.find_all('table',attrs={'class':'table4'})[-1]\n",
    "    if \"Data Not Available\" in table_content.text:\n",
    "         return {}\n",
    "    \n",
    "    table = get_table_simple(table_content)\n",
    "    dates = table[2]\n",
    "    rows = table[3:]\n",
    "    ratios = {}\n",
    "    ratios['dates'] = dates\n",
    "    \n",
    "    for row in rows:\n",
    "        if len(row)>1:\n",
    "            ratios[row[0]] = ffloat_list(row[1:])\n",
    "    \n",
    "    needed_keys = [('dates','ratios_dates'),\n",
    "                   ('Diluted EPS (Rs.)','ratios_diluted_eps'),\n",
    "                   ('Revenue from Operations/Share (Rs.)','ratios_revenue_per_share'),\n",
    "                   ('PBT/Share (Rs.)','ratios_pbt_per_share'),\n",
    "                   ('PBT Margin (%)','ratios_pbt_margin_per_share'),\n",
    "                   ('Total Debt/Equity (X)','ratios_de'),\n",
    "                   ('Asset Turnover Ratio (%)','ratios_asset_turnover_ratio'),\n",
    "                   ('Current Ratio (X)','ratios_cr'),\n",
    "                   ('EV/EBITDA (X)','ratios_ev_by_ebitda'),\n",
    "                   ('Price/BV (X)','ratios_pb')]\n",
    "    \n",
    "    ratios = { your_key[1]: ratios[your_key[0]] if your_key[0] in ratios else [] for your_key in needed_keys }\n",
    "    return ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T09:29:17.421905Z",
     "start_time": "2018-08-10T09:29:17.403654Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_past_prices(sc_id):\n",
    "    bse_url = \"https://www.moneycontrol.com/tech_charts/bse/his/%s.csv\"%sc_id\n",
    "    nse_url = \"https://www.moneycontrol.com/tech_charts/nse/his/%s.csv\"%sc_id\n",
    "    \n",
    "    past_prices_nse = pd.read_csv(nse_url,header=None,names=['open','high','low','close','volume',1,2,3,4])[['open','high','low','close','volume']]\n",
    "    past_prices_nse.index = pd.to_datetime(past_prices_nse.index)\n",
    "    \n",
    "    past_prices_bse = pd.read_csv(bse_url,header=None,names=['open','high','low','close','volume',1,2,3,4])[['open','high','low','close','volume']]\n",
    "    past_prices_bse.index = pd.to_datetime(past_prices_bse.index)\n",
    "    \n",
    "    \n",
    "    if len(past_prices_nse)>=len(past_prices_bse):\n",
    "        past_prices = past_prices_nse\n",
    "    else:\n",
    "        past_prices = past_prices_bse\n",
    "    return past_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:44:24.090463Z",
     "start_time": "2018-08-12T10:44:23.672041Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_scrip_info(url,name):\n",
    "    original_url = url\n",
    "    key_val_pairs = {}\n",
    "    key_val_pairs[\"original_url\"] = original_url\n",
    "    if not url.startswith(\"http\"):\n",
    "        url = \"https://www.moneycontrol.com\"+url\n",
    "    try:\n",
    "        page_response = requests.get(url, timeout=240)\n",
    "        page_content = BeautifulSoup(page_response.content, \"html.parser\")\n",
    "        scrip_name = name\n",
    "        price = ffloat(page_content.find('div',attrs={'id':'Nse_Prc_tick_div'}).text.split(\" \")[0].replace(',',''))\n",
    "        name = page_content.find('h1',attrs={'class':'company_name'}).text\n",
    "        \n",
    "        yearly_high = page_content.find('span',attrs={'id':'n_52high'}).text.strip()\n",
    "        yearly_low = page_content.find('span',attrs={'id':'n_52low'}).text.strip()\n",
    "        html_data_content = page_content.find('div', attrs={'id': 'mktdet_1'})\n",
    "        \n",
    "        petable = get_table_simple(get_children(html_data_content)[0],is_table_tag=False)\n",
    "        pbtable = get_table_simple(get_children(html_data_content)[1],is_table_tag=False)\n",
    "        \n",
    "        side_nav = page_content.find('dl',attrs={'id':'slider'})\n",
    "        ratio_url = side_nav.find_all('dd')[2].find_all('a')[7]['href']\n",
    "        ratio_url = \"https://www.moneycontrol.com\"+ratio_url\n",
    "        ratios = get_ratios(ratio_url)\n",
    "        \n",
    "        \n",
    "        volume = ffloat(page_content.find('span',attrs={'id':'nse_volume'}).text)\n",
    "        \n",
    "        sc_id = page_content.find('input',attrs={'id':'sc_id'}).get('value').lower()\n",
    "        \n",
    "        key_val_pairs = {**key_val_pairs, **ratios}\n",
    "        \n",
    "        past_prices = get_past_prices(sc_id)\n",
    "        \n",
    "        data_table = list()\n",
    "        data_table.extend(petable)\n",
    "        data_table.extend(pbtable)\n",
    "        \n",
    "\n",
    "        for row in data_table:\n",
    "            k = row[0]\n",
    "            if len(row)<2:\n",
    "                v=None\n",
    "            else:\n",
    "                v = row[1].split(\" \")[0].replace(',','')\n",
    "            key_val_pairs[k]=v\n",
    "\n",
    "        \n",
    "\n",
    "        key_val_pairs[\"pe\"] = ffloat(key_val_pairs.pop('P/E'))\n",
    "        key_val_pairs[\"book_value\"] = ffloat(key_val_pairs.pop('BOOK VALUE (Rs)'))\n",
    "        key_val_pairs[\"deliverables\"] = ffloat(key_val_pairs.pop('DELIVERABLES (%)'))\n",
    "        key_val_pairs[\"eps\"] = ffloat(key_val_pairs.pop('EPS (TTM)'))\n",
    "        key_val_pairs[\"industry_pe\"] = ffloat(key_val_pairs.pop('INDUSTRY P/E'))\n",
    "        if 'MARKET CAP (Rs Cr)' in key_val_pairs:\n",
    "            key_val_pairs[\"market_cap\"] = key_val_pairs.pop('MARKET CAP (Rs Cr)')\n",
    "        elif '**MARKET CAP (Rs Cr)' in key_val_pairs:\n",
    "            key_val_pairs[\"market_cap\"] = key_val_pairs.pop('**MARKET CAP (Rs Cr)')\n",
    "        key_val_pairs[\"market_cap\"] = ffloat(key_val_pairs[\"market_cap\"])\n",
    "        key_val_pairs[\"pb\"] = ffloat(key_val_pairs.pop('PRICE/BOOK'))\n",
    "        key_val_pairs[\"pc\"] = ffloat(key_val_pairs.pop('P/C'))\n",
    "        key_val_pairs['price'] = ffloat(price)\n",
    "        key_val_pairs['volume'] = volume\n",
    "        key_val_pairs[\"name\"] = name\n",
    "        key_val_pairs[\"scrip_name\"] = scrip_name\n",
    "        key_val_pairs[\"yearly_low\"] = ffloat(yearly_low)\n",
    "        key_val_pairs[\"yearly_high\"] = ffloat(yearly_high)\n",
    "\n",
    "        key_val_pairs['past_prices'] = past_prices\n",
    "        key_val_pairs['de'] = np.nan\n",
    "        key_val_pairs['ev_by_ebitda'] = np.nan\n",
    "        if \"ratios_ev_by_ebitda\" in key_val_pairs and len(key_val_pairs[\"ratios_ev_by_ebitda\"])>0:\n",
    "            key_val_pairs['ev_by_ebitda'] = key_val_pairs[\"ratios_ev_by_ebitda\"][0]\n",
    "        \n",
    "        if \"ratios_de\" in key_val_pairs and len(key_val_pairs[\"ratios_de\"])>0:\n",
    "            key_val_pairs['de'] = key_val_pairs[\"ratios_de\"][0]\n",
    "        key_val_pairs['failure'] = False\n",
    "\n",
    "        del key_val_pairs['DIV (%)']\n",
    "        del key_val_pairs['DIV YIELD.(%)']\n",
    "        del key_val_pairs['FACE VALUE (Rs)']\n",
    "        del key_val_pairs['Market Lot']\n",
    "    except Exception as e:\n",
    "        key_val_pairs['failure'] = True\n",
    "        key_val_pairs['err'] = \"Error for: %s\"%original_url\n",
    "        print(key_val_pairs['err'])\n",
    "        return key_val_pairs\n",
    "        \n",
    "    return key_val_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T10:27:45.677932Z",
     "start_time": "2018-08-10T10:27:45.664308Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_scrip_info_by_nse_name(nse_name):\n",
    "    url = \"https://www.moneycontrol.com/mccode/common/autosuggesion.php?classic=true&query=%s&type=1&format=json\"%nse_name\n",
    "    page_response = requests.get(url, timeout=240)\n",
    "    json_text = page_response.text\n",
    "    data = json.loads(json_text)\n",
    "    if len(data)>1:\n",
    "        scrips = pd.DataFrame.from_records(data)[\"pdt_dis_nm\"].values\n",
    "        idx = list(map(lambda x:BeautifulSoup(x, \"html.parser\").find(\"span\").text.split(\",\")[1].strip(),scrips)).index(nse_name)\n",
    "        scrip_url = data[idx]['link_src']\n",
    "    else:\n",
    "        scrip_url = data[0]['link_src']\n",
    "    return get_scrip_info(scrip_url,nse_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Company Analysis and Filtering \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generic Filter one variable upper lower limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T10:24:31.580961Z",
     "start_time": "2018-08-10T10:24:31.562380Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_generic_filter(param_name,lower_limit=None,upper_limit=None,\n",
    "                                     replacement_nan=None,replacement_not_present=None):\n",
    "    def filter_fn(stock_detail):\n",
    "        param = replacement_not_present\n",
    "        if param_name in stock_detail:\n",
    "            param = ffloat(stock_detail[param_name])\n",
    "            \n",
    "        if np.isnan(param):\n",
    "            param = replacement_nan\n",
    "        \n",
    "        if param is None or np.isnan(param):\n",
    "            return False\n",
    "        \n",
    "        if param<=upper_limit and param>=lower_limit:\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    return filter_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T10:26:23.609586Z",
     "start_time": "2018-08-10T10:26:23.600460Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_company_details(nse_names,\n",
    "                            threadpool_size=8):\n",
    "    batch_size = 5*threadpool_size\n",
    "    pool = ThreadPool(threadpool_size)\n",
    "    scrip_details = pool.map(get_scrip_info_by_nse_name, nse_names)\n",
    "    failures = list(filter(lambda x:x['failure'],scrip_details))\n",
    "    successes = list(filter(lambda x:not x['failure'],scrip_details))\n",
    "    successes={scrip['scrip_name']:scrip for scrip in successes}\n",
    "    return successes,failures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:42:32.455169Z",
     "start_time": "2018-08-10T11:41:39.664636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for: http://www.moneycontrol.com/india/stockpricequote/pharmaceuticals/aartidrugs/AD\n",
      "Error for: http://www.moneycontrol.com/india/stockpricequote/chemicals/atul/A06\n",
      "Error for: http://www.moneycontrol.com/india/stockpricequote/auto23wheelers/bajajauto/BA10\n",
      "Error for: http://www.moneycontrol.com/india/stockpricequote/pharmaceuticals/aurobindopharma/AP\n",
      "Error for: http://www.moneycontrol.com/india/stockpricequote/mediaentertainment/dbcorp/C13\n",
      "Error for: http://www.moneycontrol.com/india/stockpricequote/bankspublicsector/bankofbaroda/BOB\n",
      "Error for: http://www.moneycontrol.com/india/stockpricequote/drycells/evereadyindustriesindia/EII02\n",
      "Error for: http://www.moneycontrol.com/india/stockpricequote/pharmaceuticals/divislaboratories/DL03\n",
      "Error for: http://www.moneycontrol.com/india/stockpricequote/autolcvshcvs/eichermotors/EM\n",
      "Error for: http://www.moneycontrol.com/india/stockpricequote/pharmaceuticals/glenmarkpharma/GP08\n",
      "Error for: http://www.moneycontrol.com/india/stockpricequote/engines/greavescotton/GC20\n",
      "Error for: http://www.moneycontrol.com/india/stockpricequote/banksprivatesector/hdfcbank/HDF01\n",
      "Error for: http://www.moneycontrol.com/india/stockpricequote/itc/itc/ITC\n",
      "Error for: http://www.moneycontrol.com/india/stockpricequote/banksprivatesector/kotakmahindrabank/KMB\n",
      "Error for: http://www.moneycontrol.com/india/stockpricequote/powertransmissionequipment/kecinternational/KEC04\n"
     ]
    }
   ],
   "source": [
    "some_nse_companies = [\"AARTIDRUGS\",\"ATUL\",\"AUROPHARMA\",\"BAJAJ-AUTO\",\"BANKBARODA\",\n",
    "                     \"DBCORP\",\"DIVISLAB\",\"EVEREADY\",\"EICHERMOT\",\n",
    "                     \"GLENMARK\",\"GREAVESCOT\",\"HDFCBANK\",\"ITC\",\"KOTAKBANK\",\"KEC\"]\n",
    "successes,failures = get_all_company_details(some_nse_companies,\n",
    "                        threadpool_size=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:42:32.472018Z",
     "start_time": "2018-08-10T11:42:32.457844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(successes.keys())\n",
    "len(failures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:42:36.058413Z",
     "start_time": "2018-08-10T11:42:36.013873Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import dill\n",
    "with open('tutorial_results.pkl', 'wb') as f:\n",
    "    dill.dump(successes, f)\n",
    "    dill.dump(failures, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read from File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T06:24:16.347046Z",
     "start_time": "2018-07-30T06:24:16.331909Z"
    }
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "with open('tutorial_results.pkl', 'rb') as f:\n",
    "    successes = dill.load(f)\n",
    "    failures = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portfolio Selection based on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:28:43.197959Z",
     "start_time": "2018-08-10T11:28:43.190189Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_companies(all_scrips,filters=[]):\n",
    "    scrip_details = list(all_scrips.values())\n",
    "    \n",
    "    for i in range(len(filters)):\n",
    "        scrip_details = list(filter(filters[i],scrip_details))\n",
    "    \n",
    "    return scrip_details\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:29:50.101354Z",
     "start_time": "2018-08-10T11:29:50.092288Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_df_from_scrip_details(scrip_details):\n",
    "    other_cols = ['name','scrip_name']\n",
    "    numeric_cols = ['price', \n",
    "                    'market_cap', 'pb', 'pe','de']\n",
    "    \n",
    "    \n",
    "    all_cols = other_cols+numeric_cols\n",
    "    scrip_details = [{ your_key: scrip[your_key] for your_key in all_cols } for scrip in scrip_details]\n",
    "    scrip_details = pd.DataFrame.from_records(scrip_details)\n",
    "    scrip_details[numeric_cols] = scrip_details[numeric_cols].applymap(ffloat)\n",
    "    scrip_details = scrip_details[all_cols]\n",
    "    return scrip_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:42:43.907548Z",
     "start_time": "2018-08-10T11:42:43.879357Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pe_filter = get_generic_filter(\"pe\",lower_limit=0,upper_limit=20,\n",
    "                                     replacement_nan=-1,replacement_not_present=-1)\n",
    "pb_filter = get_generic_filter(\"pb\",lower_limit=0,upper_limit=4,\n",
    "                                     replacement_nan=-1,replacement_not_present=-1)\n",
    "filtered_companies = filter_companies(successes,filters=[pe_filter,pb_filter])\n",
    "get_df_from_scrip_details(filtered_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:42:46.378517Z",
     "start_time": "2018-08-10T11:42:46.358040Z"
    }
   },
   "outputs": [],
   "source": [
    "de_filter = get_generic_filter(\"de\",lower_limit=0,upper_limit=0.5,\n",
    "                                     replacement_nan=0,replacement_not_present=0)\n",
    "filtered_companies = filter_companies(successes,filters=[pe_filter,pb_filter,de_filter])\n",
    "get_df_from_scrip_details(filtered_companies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we see which filter passed and failed for different companies. This will help us understand why certain companies were rejected by our filtering process earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:31:38.502214Z",
     "start_time": "2018-08-10T11:31:38.482912Z"
    }
   },
   "outputs": [],
   "source": [
    "def score_company_on_filters(all_scrips,filters={}):\n",
    "    all_scrips = list(all_scrips.values())\n",
    "    other_cols = ['name','scrip_name']\n",
    "    numeric_cols = ['price','market_cap', 'pb', 'pe','de']\n",
    "    all_cols = other_cols+list(filters.keys())+numeric_cols\n",
    "    scrip_details = []\n",
    "    for scrip in all_scrips:\n",
    "        for key in filters.keys():\n",
    "            scrip[key] = filters[key](scrip)\n",
    "        scrip_detail = { your_key: scrip[your_key] for your_key in all_cols }\n",
    "        \n",
    "        scrip_details.append(scrip_detail)\n",
    "        \n",
    "    scrip_details = pd.DataFrame.from_records(scrip_details)\n",
    "    scrip_details[numeric_cols] = scrip_details[numeric_cols].applymap(ffloat)\n",
    "    scrip_details = scrip_details[all_cols]\n",
    "    return scrip_details\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:42:52.334219Z",
     "start_time": "2018-08-10T11:42:52.325941Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_df = score_company_on_filters(successes,filters={\"pe_filter\":pe_filter,\"pb_filter\":pb_filter,\"de_filter\":de_filter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:42:53.594411Z",
     "start_time": "2018-08-10T11:42:53.565674Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PE vs MarketCap Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:46:10.740836Z",
     "start_time": "2018-08-10T11:46:10.106769Z"
    }
   },
   "outputs": [],
   "source": [
    "pe_list = []\n",
    "mcap_list = []\n",
    "for key in successes.keys():\n",
    "    prices_df = successes[key]['past_prices']\n",
    "    \n",
    "    pe = successes[key]['pe']\n",
    "    mcap = successes[key]['market_cap']\n",
    "    \n",
    "    pe_list.append(pe)\n",
    "    mcap_list.append(mcap)\n",
    "    \n",
    "plt.figure(figsize=(12,6))\n",
    "ax = sns.regplot(x=np.array(pe_list), y=np.array(mcap_list),fit_reg=True)\n",
    "ax.set_xlim([10,40])\n",
    "ax.set_ylim([0,6e5])\n",
    "plt.xlabel(\"PE Ratio\");\n",
    "plt.ylabel(\"Market Cap in Crores (10 Million INR.)\");\n",
    "\n",
    "plt.show()\n",
    "plt.figure(figsize=(12,6))\n",
    "ax = sns.regplot(x=np.array(mcap_list), y=np.array(pe_list),fit_reg=True,logx=True)\n",
    "plt.ylabel(\"PE Ratio\");\n",
    "plt.xlabel(\"Market Cap in Crores (10 Million INR.)\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Price Volume Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:38:42.793214Z",
     "start_time": "2018-08-10T11:38:42.777215Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_price_chart(stock_df,name,days=1095,ewmas=[],other_technical_indicators=[]):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    ts_df = stock_df.tail(days)\n",
    "    handles = []\n",
    "    p1, = plt.plot(ts_df.index, ts_df['close'],label=\"price\")\n",
    "    handles.append(p1)\n",
    "    for ewma in ewmas:\n",
    "        y = ts_df['close'].ewm(span=ewma).mean()\n",
    "        p2, = plt.plot(ts_df.index, y,label=\"%s day ewma\"%ewma)\n",
    "        handles.append(p2)\n",
    "    plt.legend(handles=handles)\n",
    "    plt.title(name)\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:38:40.571883Z",
     "start_time": "2018-08-10T11:38:40.535883Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_price_volume_chart(stock_df,name,days=1095,ewmas=[],other_technical_indicators=[]):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    top = plt.subplot2grid((6,6), (0, 0), rowspan=4, colspan=6)\n",
    "    bottom = plt.subplot2grid((6,6), (4,0), rowspan=2, colspan=6)\n",
    "    ts_df = stock_df.tail(days)\n",
    "    handles = []\n",
    "    p1, = top.plot(ts_df.index, ts_df['close'],label=\"price\")\n",
    "    handles.append(p1)\n",
    "    for ewma in ewmas:\n",
    "        y = ts_df['close'].ewm(span=ewma).mean()\n",
    "        p2, = top.plot(ts_df.index, y,label=\"%s day ewma\"%ewma)\n",
    "        handles.append(p2)\n",
    "    top.legend(handles=handles)\n",
    "    bottom.bar(ts_df.index, ts_df['volume']) \n",
    "    bottom.set_ylim([ts_df['volume'].min(),ts_df['volume'].max()])\n",
    "    top.axes.get_xaxis().set_visible(False)\n",
    "    top.set_title(name)\n",
    "    top.set_ylabel('Closing Price')\n",
    "    bottom.set_ylabel('Volume')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:48:55.137699Z",
     "start_time": "2018-08-10T11:48:39.065913Z"
    }
   },
   "outputs": [],
   "source": [
    "hero = get_scrip_info_by_nse_name('HEROMOTOCO')\n",
    "exide = get_scrip_info_by_nse_name('EXIDEIND')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:48:56.998627Z",
     "start_time": "2018-08-10T11:48:56.361205Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_price_volume_chart(hero['past_prices'],\"HERO Motocorp\",days=252,ewmas=[7,45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:49:40.663393Z",
     "start_time": "2018-08-10T11:49:40.022270Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_price_volume_chart(exide['past_prices'],\"Exide\",days=252,ewmas=[7,45])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Returns analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:52:38.696142Z",
     "start_time": "2018-08-10T11:52:38.679913Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_returns_chart(stocks,days=252):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    stocks = {key:stocks[key].tail(days).apply(lambda x: x / x[0]) for key in stocks.keys()}\n",
    "    handles = []\n",
    "    for key in stocks.keys():\n",
    "        y = stocks[key]['close']\n",
    "        p2, = plt.plot(stocks[key].index, y,label=key)\n",
    "        handles.append(p2)\n",
    "    plt.legend(handles=handles)\n",
    "    plt.title(\"Comparative returns\")\n",
    "    plt.ylabel('Comparative Returns')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:49:50.759872Z",
     "start_time": "2018-08-10T11:49:50.430915Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_returns_chart({\"HERO\":hero['past_prices'],\n",
    "                       \"EXIDE\":exide['past_prices']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Volatility analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:52:22.416373Z",
     "start_time": "2018-08-10T11:52:22.393100Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_percent_change_chart(stocks,days=252):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    stocks = {key:stocks[key].tail(days).pct_change()*100 for key in stocks.keys()}\n",
    "    handles = []\n",
    "    for key in stocks.keys():\n",
    "        stocks[key]['name'] = key\n",
    "        y = stocks[key]['close']\n",
    "        p2, = plt.plot(stocks[key].index, y,label=key)\n",
    "        handles.append(p2)\n",
    "    all_stocks = pd.concat(list(stocks.values()))\n",
    "    plt.legend(handles=handles)\n",
    "    plt.title(\"Daily Percent Changes Chart\")\n",
    "    plt.ylabel('Daily Percent Changes')\n",
    "    plt.show()\n",
    "    fig, ax = plt.subplots(figsize=(16,8))\n",
    "    sns.boxplot(x=\"name\", y=\"close\", data=all_stocks,ax=ax);\n",
    "    ax.xaxis.set_tick_params(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:52:25.353914Z",
     "start_time": "2018-08-10T11:52:24.688174Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "generate_percent_change_chart({\"HERO\":hero['past_prices'],\n",
    "                       \"EXIDE\":exide['past_prices']},days=252)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Returns and Volatility of all companies we used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:52:46.090385Z",
     "start_time": "2018-08-10T11:52:46.083899Z"
    }
   },
   "outputs": [],
   "source": [
    "all_scrip_prices_df = {scrip[\"scrip_name\"]:scrip['past_prices'] for scrip in successes.values()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:52:49.008483Z",
     "start_time": "2018-08-10T11:52:47.323919Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_returns_chart(all_scrip_prices_df)\n",
    "generate_percent_change_chart({scrip[\"scrip_name\"]:scrip['past_prices'] for scrip in successes.values()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nifty 50, Nifty 100, Nifty midcap 50 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:27:14.872234Z",
     "start_time": "2018-08-10T11:27:00.596523Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n50_url = \"http://www.moneycontrol.com/tech_charts/nse/his/nifty.csv\"\n",
    "n50 = pd.read_csv(n50_url,header=None,names=['open','high','low','close','volume'])[['open','high','low','close','volume']]\n",
    "n50.index = pd.to_datetime(n50.index)\n",
    "\n",
    "\n",
    "n100_url = \"http://www.moneycontrol.com/tech_charts/nse/his/cnx_100.csv\"\n",
    "n100 = pd.read_csv(n100_url,header=None,names=['open','high','low','close','volume'])[['open','high','low','close','volume']]\n",
    "n100.index = pd.to_datetime(n100.index)\n",
    "\n",
    "nmid_url = \"http://www.moneycontrol.com/tech_charts/nse/his/nifty_midcap_50.csv\"\n",
    "nmid = pd.read_csv(nmid_url,header=None,names=['open','high','low','close','volume'])[['open','high','low','close','volume']]\n",
    "nmid.index = pd.to_datetime(nmid.index)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T11:27:17.158753Z",
     "start_time": "2018-08-10T11:27:15.992945Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "generate_price_chart(n50,\"nifty 50\",days=1095,ewmas=[30,120])\n",
    "generate_price_chart(n100,\"nifty 100\",days=1095,ewmas=[30,120])\n",
    "generate_price_chart(nmid,\"nifty midcap 50\",days=1095,ewmas=[30,120])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T19:30:30.168124Z",
     "start_time": "2018-07-27T19:30:29.745907Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_returns_chart({\"nifty 50\":n50,\"nifty 100\":n100,\"nifty midcap 50\":nmid,\"hero\":hero['past_prices']['all_past_prices']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T19:30:28.570097Z",
     "start_time": "2018-07-27T19:30:27.703439Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "generate_percent_change_chart({\"nifty 50\":n50,\"nifty 100\":n100,\"nifty midcap 50\":nmid,\"hero\":hero['past_prices']['all_past_prices']},days=1095)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://ntguardian.wordpress.com/2016/09/19/introduction-stock-market-data-python-1/\n",
    "- https://mapattack.wordpress.com/2017/02/14/python-for-stocks-2/\n",
    "\n",
    "more involved articles:\n",
    "\n",
    " - https://ntguardian.wordpress.com/2018/07/17/stock-data-analysis-python-v2/\n",
    " - https://nextjournal.com/hisham/stock-market\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
